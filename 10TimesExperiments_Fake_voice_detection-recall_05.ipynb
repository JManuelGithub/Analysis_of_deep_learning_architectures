{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7a0cc-7cf8-4e02-a258-b1978931a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "#from torch.nn import functional as F\n",
    "from torch import flatten\n",
    "from platform import python_version\n",
    "sample_rate = 16000\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print('Python Version :',python_version())\n",
    "print('Torch Version:',torch.__version__)\n",
    "print('Torch Audio Version :',torchaudio.__version__)\n",
    "print('Is CUDA available? :', torch.cuda.is_available())\n",
    "print('Device name :',torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "print('Backend de audio disponibles',str(torchaudio.list_audio_backends()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c089dfe-980b-4ea3-9edb-7a1af06847e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   \n",
    "def create_dataset(dataset_path):\n",
    "    clases = {'fake':torch.tensor([0]), 'real':torch.tensor([1])}\n",
    "    X=torch.tensor(())\n",
    "    y=torch.tensor(())\n",
    "    class_path = os.listdir(dataset_path)\n",
    "    for clase in class_path:\n",
    "        file_path = os.path.join(dataset_path,clase)\n",
    "        for file in os.listdir(file_path):\n",
    "            audio,audio_rate = torchaudio.load(os.path.join(file_path,file), backend='soundfile')\n",
    "            #mfcc = transform(audio)\n",
    "            X = torch.cat((X,audio),0)\n",
    "            y = torch.cat((y,clases[clase]),0)\n",
    "    #return sub_dt(X,y)\n",
    "    return X.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b86e6-8b56-4350-a938-097530b24a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testing, y_testing = create_dataset('../for-2seconds/testing')#Manually created from training set\n",
    "X_training, y_training = create_dataset('../for-2seconds/training')\n",
    "X_valid, y_valid = create_dataset('../for-2seconds/validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b237f2cd-2123-47d0-8802-274cee9e3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training.shape, y_training.shape, X_valid.shape, y_valid.shape, X_testing.shape, y_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc7071-2c58-408e-8bb8-116a81972bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_fft = 2048\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_mels = 256\n",
    "n_mfcc = 8\n",
    "mfcc_transform = T.MFCC(\n",
    "    sample_rate=16000,\n",
    "    n_mfcc=n_mfcc,\n",
    "    melkwargs={\"n_fft\": n_fft,\"n_mels\": n_mels,\"hop_length\": hop_length,\"mel_scale\": \"htk\",}\n",
    ")\n",
    "\n",
    "n_fft = 2048\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_lfcc = 8\n",
    "\n",
    "lfcc_transform = T.LFCC(\n",
    "    sample_rate=16000,\n",
    "    n_lfcc=n_lfcc,\n",
    "    speckwargs={\n",
    "        \"n_fft\": n_fft,\n",
    "        \"win_length\": win_length,\n",
    "        \"hop_length\": hop_length,\n",
    "    },\n",
    ")\n",
    "\n",
    "def plot_waveform(waveform, sr, title=\"Waveform\", ax=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sr\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(num_channels, 1)\n",
    "    ax.plot(time_axis, waveform[0], linewidth=1)\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim([0, time_axis[-1]])\n",
    "    ax.set_title(title)\n",
    "\n",
    "def plot_spectrogram(spectrogram, title=None, ylabel=\"freq_bin\", ax=None, ):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.imshow(spectrogram, origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c089c1-eee7-45dc-a1fe-8a0b0cffe544",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio,audio_rate = torchaudio.load('../for-2seconds/validation\\\\fake\\\\file15502.mp3.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav', backend='soundfile')\n",
    "#plot_waveform(audio)\n",
    "fig, axs = plt.subplots(3, 1)\n",
    "plot_waveform(audio, audio_rate, title=\"Original waveform\", ax=axs[0])\n",
    "plot_spectrogram(mfcc_transform(audio)[0], title=\"MFCC\", ax=axs[1])\n",
    "plot_spectrogram(lfcc_transform(audio)[0], title=\"LFCC\", ax=axs[2])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3ed5c2-9bb9-45d4-825f-fe037dfe16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio,audio_rate = torchaudio.load('../for-2seconds/validation\\\\real\\\\file5.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav', backend='soundfile')\n",
    "#plot_waveform(audio)\n",
    "fig, axs = plt.subplots(3, 1)\n",
    "plot_waveform(audio, audio_rate, title=\"Original waveform\", ax=axs[0])\n",
    "plot_spectrogram(mfcc_transform(audio)[0], title=\"MFCC\", ax=axs[1])\n",
    "plot_spectrogram(lfcc_transform(audio)[0], title=\"LFCC\", ax=axs[2])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4995a5-89d6-4ce1-9c6e-e2b2978ffed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23962df8-05ee-41c6-8b76-8a0c91f40db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = mfcc_transform(audio)\n",
    "mfcc = mfcc[:, :]\n",
    "mfcc.shape,flatten(mfcc,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f756f7-0732-4a99-a9d1-7105f6bac9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcc = lfcc_transform(audio)\n",
    "lfcc = lfcc[:, :]\n",
    "lfcc.shape,flatten(lfcc,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b4109-0e9c-4819-bc5f-49c7bc3fad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mticker\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "import torch.nn as nn\n",
    "\n",
    "s = nn.Softmax(dim=0)\n",
    "def plot_loss_acc(hist):\n",
    "    x_arr=np.arange(len(hist[0]))+1\n",
    "    fig=plt.figure(figsize=(12,4))\n",
    "    ax=fig.add_subplot(1,2,1)\n",
    "    ax.ticklabel_format(style='plain', axis='x', useOffset=False)\n",
    "    ax.xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    ax.plot(x_arr,hist[0], '-o', label='Train Loss')\n",
    "    ax.plot(x_arr,hist[1], '--<', label='Valid Loss')\n",
    "    ax.legend(fontsize=15)\n",
    "    ax.set_xlabel('Epoch', size=15)\n",
    "    ax.set_ylabel('Loss', size=15)\n",
    "    ax=fig.add_subplot(1,2,2)\n",
    "    ax.ticklabel_format(style='plain', axis='x', useOffset=False)\n",
    "    ax.xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    ax.plot(x_arr,hist[2], '-o', label='Train Acc')\n",
    "    ax.plot(x_arr,hist[3], '--<', label='Valid Acc')\n",
    "    ax.legend(fontsize=15)\n",
    "    ax.set_xlabel('Epoch', size=15)\n",
    "    ax.set_ylabel('Accuracy', size=15)\n",
    "    ax.set_ylim(0.45,1.05)\n",
    "    plt.show()\n",
    "    \n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format). \n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time\n",
    "#torch.manual_seed(42)\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          num_epochs: int,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          valid_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          device: torch.device):\n",
    "    epochs=num_epochs\n",
    "    loss_hist_train = [0]*epochs\n",
    "    accuracy_hist_train = [0]*epochs\n",
    "    loss_hist_valid = [0]*epochs\n",
    "    accuracy_hist_valid=[0]*epochs\n",
    "    model = model.to(device)\n",
    "    train_time_start = timer()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            #x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            #x_batch, y_batch = x_batch.unsqueeze(1), y_batch.unsqueeze(1)\n",
    "            \n",
    "            pred = model(x_batch)[:,0]\n",
    "            #print('pred-->',pred)\n",
    "            #print('y--->',y_batch)\n",
    "            #print('is correct--->',((pred>=0.5).float() == y_batch).float())\n",
    "            loss=loss_fn(pred,y_batch.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch]+=loss.item()*y_batch.size(0)\n",
    "            is_correct=((pred>=0.5).float() == y_batch).float()\n",
    "            #print(is_correct.sum().item())\n",
    "            accuracy_hist_train[epoch]+=is_correct.sum().item()\n",
    "        loss_hist_train[epoch]/=len(train_dataloader.dataset)\n",
    "        accuracy_hist_train[epoch]/=len(train_dataloader.dataset)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dataloader:\n",
    "                #x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                #x_batch, y_batch = x_batch.unsqueeze(1), y_batch.unsqueeze(1)\n",
    "                pred = model(x_batch)[:,0]\n",
    "                #print('pred BEFORE-->',pred)\n",
    "                #pred = (torch.sigmoid(pred) + 0.5)\n",
    "                #print('pred-->',pred)\n",
    "                #print('y--->',y_batch)\n",
    "                #print('is correct--->',((pred>=0.5).float() == y_batch).float())\n",
    "                loss=loss_fn(pred,y_batch.float())\n",
    "                loss_hist_valid[epoch]+=loss.item()*y_batch.size(0)\n",
    "                is_correct=((pred>=0.5).float() == y_batch).float()\n",
    "                accuracy_hist_valid[epoch]+=is_correct.sum().item()\n",
    "                #print('ACC',accuracy_hist_valid[epoch])\n",
    "        loss_hist_valid[epoch]/=len(valid_dataloader.dataset)\n",
    "        accuracy_hist_valid[epoch]/=len(valid_dataloader.dataset)\n",
    "        #print('ACC_TOTAL---->',accuracy_hist_valid[epoch])\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(f'Epoch:{epoch+1}---Train Acc:{accuracy_hist_train[epoch]*100:.3f}%---Valid Acc:{accuracy_hist_valid[epoch]*100:.3f}%')\n",
    "    train_time_end = timer()\n",
    "    total_train_time = print_train_time(start=train_time_start, \n",
    "                                           end=train_time_end,\n",
    "                                           device=str(next(model.parameters()).device))\n",
    "    return [loss_hist_train, loss_hist_valid, accuracy_hist_train,accuracy_hist_valid], total_train_time\n",
    "\n",
    "def test(model: torch.nn.Module,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          device: torch.device):\n",
    "    loss_test = 0.0\n",
    "    accuracy_test=0.0\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            pred = model(x_batch)[:,0]\n",
    "            loss=loss_fn(pred,y_batch.float())\n",
    "            #print(y_batch.size(0))\n",
    "            loss_test+=loss.item()*y_batch.size(0)\n",
    "            pred_round = (pred>=0.5).float()\n",
    "            pred_log = torch.sigmoid(pred)\n",
    "            #print(pred_log)\n",
    "            is_correct=(pred_round == y_batch).float()\n",
    "            accuracy_test+=is_correct.sum().item()\n",
    "            #print('ACC',accuracy_hist_valid[epoch])\n",
    "    loss_test/=len(test_dataloader.dataset)\n",
    "    accuracy_test/=len(test_dataloader.dataset)\n",
    "    confmat = confusion_matrix(y_true=y_batch.cpu(), y_pred=pred_round.cpu())\n",
    "    precision = precision_score(y_true=y_batch.cpu(), y_pred=pred_round.cpu())\n",
    "    recall = recall_score(y_true=y_batch.cpu(), y_pred=pred_round.cpu())\n",
    "    f1 = f1_score(y_true=y_batch.cpu(), y_pred=pred_round.cpu())\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_batch.cpu(), y_score=pred_log.cpu())\n",
    "    roc_auc = roc_auc_score(y_true=y_batch.cpu(), y_score=pred_log.cpu())\n",
    "    #print(f'fpr:{fpr}, tpr:{tpr}')\n",
    "    fnr = 1 - tpr\n",
    "    eer_1 = fpr[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    eer_2 = fnr[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    eer = (eer_1+eer_2)/2\n",
    "    print(f'---Test Acc:{accuracy_test*100:.3f}%')\n",
    "    return [loss_test,confmat,precision,recall,f1,roc_auc,eer, accuracy_test]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c2a7e-f195-4f22-8266-1d6cd076d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#neural network model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, max_pool_sizes, in_features = 1, out_dim=1, conv_out = 3840):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_features, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(max_pool_sizes[0], max_pool_sizes[0])\n",
    "        self.fc1 = nn.Linear(conv_out, 128)\n",
    "        self.fc2 = nn.Linear(128, out_dim)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout=nn.Dropout(p=0.25)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = self.pool(self.relu(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_size, dropout=0.0, num_layers=1, bidirectional=False, num_classes=1, type='rnn'):\n",
    "        super().__init__()\n",
    "        types_rnn = {'rnn':nn.RNN(out_channels, hidden_size, dropout=dropout, num_layers=num_layers, bidirectional=bidirectional, batch_first=True),\n",
    "                   'lstm':nn.LSTM(out_channels, hidden_size, dropout=dropout, num_layers=num_layers, bidirectional=bidirectional, batch_first=True),\n",
    "                   'gru':nn.GRU(out_channels, hidden_size, dropout=dropout, num_layers=num_layers, bidirectional=bidirectional, batch_first=True),}\n",
    "        self.rnn = types_rnn[type]\n",
    "        hidden_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu=nn.ReLU()\n",
    "        #self.softmax=nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = flatten(x,1)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class Conv2dRNN(nn.Module):\n",
    "    def __init__(self, max_pool_sizes, in_channels = 1, out_channels=1, hidden_size=512, dropout=0.0, num_layers=1, bidirectional=False, num_classes=1, type='rnn'):\n",
    "        super().__init__()\n",
    "        types_rnn = {'rnn':nn.RNN(out_channels, hidden_size, dropout=dropout, num_layers=num_layers, bidirectional=bidirectional, batch_first=True),\n",
    "                   'lstm':nn.LSTM(out_channels, hidden_size, dropout=dropout, num_layers=num_layers, bidirectional=bidirectional, batch_first=True),\n",
    "                   'gru':nn.GRU(out_channels, hidden_size, dropout=dropout, num_layers=num_layers, bidirectional=bidirectional, batch_first=True),}\n",
    "        self.rnn = types_rnn[type]\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(max_pool_sizes[0], max_pool_sizes[0])\n",
    "        #self.rnn = nn.RNN(out_channels, hidden_size, dropout=dropout, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        hidden_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout=nn.Dropout(p=0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = self.pool(self.relu(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = flatten(x, 1)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x, _ = self.rnn(x)\n",
    "        # x shape: (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        x = x[:, -1, :]  # Take the last output of LSTM \n",
    "        x = self.fc(x)\n",
    "        # x shape: (batch_size, num_classes)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9590a-22f1-44af-8168-485ca467fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class sub_dt(Dataset):\n",
    "    def __init__(self, X, y,   transform=None):\n",
    "        assert len(X)==len(y), 'Different Length'\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.transform(self.x[idx]), self.y[idx]\n",
    "        return sample\n",
    "n_fft = 2048\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_mels = 256\n",
    "n_mfcc = 256\n",
    "mfcc_transform = T.MFCC(\n",
    "    sample_rate=16000,\n",
    "    n_mfcc=n_mfcc,\n",
    "    melkwargs={\"n_fft\": n_fft,\"n_mels\": n_mels,\"hop_length\": hop_length,\"mel_scale\": \"htk\",}\n",
    ")\n",
    "mfcc_transform = mfcc_transform.to(device)\n",
    "\n",
    "#generator1 = torch.Generator().manual_seed(42)\n",
    "#alpha = int(np.floor(.1*len(dt_training)))\n",
    "\n",
    "dt_training = sub_dt(X_training, y_training, transform = mfcc_transform)\n",
    "#dt_testing, dt_training = random_split(dt_training, [alpha, len(dt_training)-alpha], generator=generator1)\n",
    "dt_testing = sub_dt(X_testing, y_testing, transform = mfcc_transform)\n",
    "dt_valid = sub_dt(X_valid, y_valid, transform = mfcc_transform)\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(dt_training, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_dataloader = DataLoader(dt_valid, batch_size=batch_size,shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(dt_testing, batch_size=len(dt_testing), shuffle=False, drop_last=False)\n",
    "#test_dataloader = DataLoader(dt_testing, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "print(f'Length of train dataloader: {len(train_dataloader)} batches of:{batch_size}')\n",
    "print(f'Length of valid dataloader: {len(valid_dataloader)} batches of:{batch_size}')\n",
    "print(f'Length of testing dataloader: {len(test_dataloader)} batches of:{len(dt_testing)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870cd2e-b111-424a-a4a8-2dd4d80b7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import floor\n",
    "\n",
    "output_rnn = dt_testing[0][0].shape[0]*dt_testing[0][0].shape[1]\n",
    "print('RNN: ',output_rnn)\n",
    "\n",
    "def cnn_output_shape(dim_in, kernel_size, stride):\n",
    "    h_out = int(floor((dim_in[0] - (kernel_size[0]-1) - 1 + stride[0]) / stride[0]))\n",
    "    w_out = int(floor((dim_in[1] - (kernel_size[1]-1) - 1 + stride[1]) / stride[1]))\n",
    "    return h_out,w_out\n",
    "\n",
    "kernel_size = (2,2)\n",
    "stride=(2,2)\n",
    "conv1 = cnn_output_shape(dim_in=(n_mfcc,63), kernel_size=kernel_size, stride=stride)\n",
    "print(conv1)\n",
    "conv2 = cnn_output_shape(dim_in=conv1, kernel_size=kernel_size, stride=stride)\n",
    "print(conv2)\n",
    "conv3 = cnn_output_shape(dim_in=conv2, kernel_size=kernel_size, stride=stride)\n",
    "print(conv3)\n",
    "conv4 = cnn_output_shape(dim_in=conv3, kernel_size=kernel_size, stride=stride)\n",
    "print(conv4)\n",
    "conv_out = 256 * conv4[0] * conv4[1]\n",
    "print('Conv: ',conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca0d061-43ea-4138-a21f-6125221b6b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(max_pool_sizes=(kernel_size, stride), in_features=1, out_dim=1, conv_out = conv_out)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)\n",
    "#print(model)\n",
    "hist,time = train(model=model, \n",
    "             num_epochs=3, \n",
    "             train_dataloader=train_dataloader, \n",
    "             valid_dataloader=valid_dataloader,\n",
    "             loss_fn=loss_fn,\n",
    "             optimizer=optimizer,\n",
    "             device=device\n",
    "            )\n",
    "plot_loss_acc(hist)\n",
    "testing = test(model=model,\n",
    "              test_dataloader=test_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              device=device)\n",
    "print(f'Testing Loss:{testing[0]:.1f}---Testing Acc:{testing[-1]*100:.2f}%')\n",
    "print(f'matrix:{testing[1]}, precision:{testing[2]}, recall:{testing[3]}, f1:{testing[4]}, auc:{testing[5]}, eer:{testing[6]}')\n",
    "#[loss_test,confmat,precision,recall,f1,roc_auc,eer, accuracy_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5bc90f-1aba-4caa-81db-bb0040a6736a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_optim(model=None,params = None, lr=0.01, momentum = 0, type = 'SGD'):\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    model.load_state_dict(params)\n",
    "    return model, loss_fn, torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "models_dict = {\n",
    "'cnn': CNN(max_pool_sizes=(kernel_size, stride), in_features=1, out_dim=1, conv_out = conv_out),\n",
    "'rnn': RNN(in_channels=1, out_channels=output_rnn, hidden_size=256, dropout=0.0, num_layers=1, bidirectional=False, num_classes=1, type='rnn'),\n",
    "'cnn_rnn': Conv2dRNN(max_pool_sizes=(kernel_size, stride), in_channels=1, out_channels=conv_out, hidden_size=256,dropout=0.0, num_layers=1, bidirectional=False, num_classes=1, type='rnn'),\n",
    "'lstm': RNN(in_channels=1, out_channels=output_rnn, hidden_size=256, dropout=0.0, num_layers=1, bidirectional=False, num_classes=1, type='lstm'),\n",
    "'cnn_lstm': Conv2dRNN(max_pool_sizes=(kernel_size, stride), in_channels=1, out_channels=conv_out, hidden_size=256,dropout=0.0, num_layers=1, bidirectional=False, num_classes=1, type='lstm'),\n",
    "'gru': RNN(in_channels=1, out_channels=output_rnn, hidden_size=256, dropout=0.0, num_layers=1, bidirectional=False, num_classes=1, type='gru'),\n",
    "'cnn_gru': Conv2dRNN(max_pool_sizes=(kernel_size, stride), in_channels=1, out_channels=conv_out, hidden_size=256,dropout=0.0, num_layers=1, bidirectional=False, num_classes=1, type='gru')\n",
    "}\n",
    "\n",
    "models = ['cnn','rnn','cnn_rnn','lstm','cnn_lstm','gru','cnn_gru']#'cnn','rnn','cnn_rnn','lstm','cnn_lstm','gru','cnn_gru'\n",
    "\n",
    "learning_rates = [0.01,0.001]#0.01,\n",
    "momentums = [0,0.1]#,0.1\n",
    "num_epochs=15\n",
    "trials=10\n",
    "results = {}\n",
    "for model_iter in models:\n",
    "    params = models_dict[model_iter].state_dict()\n",
    "    for lr in learning_rates:\n",
    "        for momento in momentums:\n",
    "            for iter in range(trials):\n",
    "                experiment = model_iter+ '/'+str(iter) + '/' + str(lr)+'/'+str(momento)\n",
    "                model, loss_fn, optimizer = get_optim(models_dict[model_iter],params, lr, momento, 'SGD')\n",
    "                print('\\n\\n'+'+'*5, experiment,'+'*5)\n",
    "                training, time = train(model=model, \n",
    "                     num_epochs=num_epochs, \n",
    "                     train_dataloader=train_dataloader, \n",
    "                     valid_dataloader=valid_dataloader,\n",
    "                     loss_fn=loss_fn,\n",
    "                     optimizer=optimizer,\n",
    "                     device=device\n",
    "                    )\n",
    "                testing = test(model=model,\n",
    "                      test_dataloader=test_dataloader,\n",
    "                      loss_fn=loss_fn,\n",
    "                      device=device)\n",
    "                results[experiment] = {'model':model_iter, \n",
    "                                       'lr':str(lr), \n",
    "                                       'momentum': str(momento), \n",
    "                                       'training_hist':training, \n",
    "                                       'testing_hist':testing, \n",
    "                                       'time':time, \n",
    "                                       'training_acc':training[2][-1],\n",
    "                                       'valid_acc': training[3][-1],\n",
    "                                       'test_acc': testing[-1],\n",
    "                                       'test_confmatrix': testing[1],\n",
    "                                       'test_precision': testing[2],\n",
    "                                       'test_recall': testing[3],\n",
    "                                       'test_f1': testing[4],\n",
    "                                       'test_auc': testing[5],\n",
    "                                       'test_eer': testing[6],\n",
    "                                      }\n",
    "\n",
    "#results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adeb2d4-27d6-466f-805d-fa43555ad839",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in results.keys():\n",
    "    print('\\n{:=^50}'.format(_))\n",
    "    print('Testing Loss:{:.3f}---Testing Accuracy:{:.3f}%'.format(results[_]['testing_hist'][0],results[_]['testing_hist'][-1]*100))\n",
    "    print('Training Time: {:.3f} sec.'.format(results[_]['time']))\n",
    "    plot_loss_acc(results[_]['training_hist'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc096a-ea70-4167-baab-52900d196096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "data = 'results_256_10iters_metrics_0_5.pkl'\n",
    "with open(data, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "        \n",
    "with open(data, 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e8eca-4c0e-4243-a1bc-3058e0795b8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f4c46-293a-4b7d-8b95-a7524283e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_agg={'time':'mean',\n",
    "         'training_acc':'mean',\n",
    "         'valid_acc':'mean',\n",
    "         'test_acc':'mean',\n",
    "        'test_precision':'mean',\n",
    "        'test_recall':'mean',\n",
    "        'test_f1':'mean',\n",
    "        'test_auc':'mean',\n",
    "         'test_eer':'mean'\n",
    "        }\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "df.drop(['training_hist', 'testing_hist','test_confmatrix'], axis=1,inplace=True)\n",
    "df.reset_index(inplace = True, drop=True)\n",
    "df_all = df.groupby(['model','lr', 'momentum']).agg(dict_agg).reset_index()\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667636e2-553a-411d-9ec0-658e3847ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.groupby(['model']).agg(dict_agg).reset_index()\n",
    "\n",
    "df_model.sort_values('test_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844ab7f-5dc9-4d59-8c79-340f2d2eae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_lr = df.groupby(['model','lr']).agg(dict_agg).reset_index()\n",
    "\n",
    "df_model_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7829a1-8190-4f9f-8e9a-92d83d1ca4b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c33a6f-f76a-48ba-a1bb-2c40742058fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "figure, axes = plt.subplots(2,2,sharex=False, figsize=(10,8), layout='tight')\n",
    "y_list=['time', 'training_acc', 'valid_acc', 'test_acc']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    \n",
    "    sns.boxplot(df, x='model',y=y_list[i], ax=ax)\n",
    "    ax.set_title(y_list[i])\n",
    "    '''\n",
    "sns.boxplot(df, x='model',y='time', ax=axes[0][0])\n",
    "sns.boxplot(df, x='model',y='training_acc', ax=axes[0][1])\n",
    "sns.boxplot(df, x='model',y='valid_acc', ax=axes[1][0])\n",
    "sns.boxplot(df, x='model',y='test_acc', ax=axes[1][1])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52d558-ab4a-42c1-8f4d-1238f51d922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(2,2,sharex=False, figsize=(10,8), layout='tight')\n",
    "y_list=['time', 'training_acc', 'valid_acc', 'test_acc']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    \n",
    "    sns.boxplot(df[df['model'].isin(['cnn', 'cnn_lstm','cnn_gru'])], x='model',y=y_list[i], ax=ax)\n",
    "    ax.set_title(y_list[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c0d20-3896-4143-9bd5-ca7551e08de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(2,2,sharex=False, figsize=(10,8), layout='tight')\n",
    "y_list=['time', 'training_acc', 'valid_acc', 'test_acc']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    \n",
    "    sns.boxplot(df[(df['model'].isin(['cnn', 'cnn_lstm','cnn_gru'])) & (df['lr']=='0.001')], x='model',y=y_list[i], ax=ax)\n",
    "    ax.set_title(y_list[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90096e9-042c-4066-aa23-0322714a00ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
